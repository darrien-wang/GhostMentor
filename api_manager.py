#!/usr/bin/env python3
"""
GhostMentor API Manager
å¤„ç†OpenAI APIç›¸å…³åŠŸèƒ½
"""

import asyncio
import base64
import io
import numpy as np
import cv2
import openai
from PIL import Image
from typing import Optional, List, Tuple, AsyncGenerator
from config_manager import config
from logger_manager import get_logger

logger = get_logger(__name__)

class APIManager:
    """OpenAI APIç®¡ç†å™¨"""
    
    def __init__(self):
        self.client = None
        self.model = config.get('openai_model', 'gpt-4o')  # ğŸ”§ æ·»åŠ æ¨¡å‹é…ç½®
        self.conversation_history: List[Tuple[str, str]] = []
        self.setup_client()
    
    def setup_client(self):
        """åˆå§‹åŒ–OpenAIå®¢æˆ·ç«¯"""
        try:
            api_key = config.get('openai_api_key')
            if not api_key:
                raise ValueError("OpenAI API key not found")
            
            self.client = openai.OpenAI(api_key=api_key)
            logger.info(f"ğŸ¤– OpenAI client initialized with model: {self.model}")
        except Exception as e:
            logger.error(f"Failed to initialize OpenAI client: {e}")
            raise
    
    def image_to_base64(self, image: Image.Image) -> str:
        """å°†PILå›¾åƒè½¬æ¢ä¸ºbase64ç¼–ç """
        try:
            # è½¬æ¢ä¸ºnumpyæ•°ç»„
            img_array = np.array(image)
            # è½¬æ¢é¢œè‰²ç©ºé—´ï¼ˆPILä½¿ç”¨RGBï¼ŒOpenCVä½¿ç”¨BGRï¼‰
            img_rgb = cv2.cvtColor(img_array, cv2.COLOR_RGB2BGR)
            # ç¼–ç ä¸ºPNG
            _, buffer = cv2.imencode('.png', img_rgb)
            # è½¬æ¢ä¸ºbase64
            img_base64 = base64.b64encode(buffer).decode('utf-8')
            logger.debug(f"Image converted to base64, size: {len(img_base64)} chars")
            return img_base64
        except Exception as e:
            logger.error(f"Error converting image to base64: {e}")
            raise
    
    def create_analysis_prompt(self, user_text: str = "") -> str:
        """åˆ›å»ºåˆ†ææç¤ºè¯"""
        if user_text.strip():
            prompt = f"""Please analyze the content on the screen and provide a structured response:

ã€Analysis & Solutionã€‘
1. Problem Analysis - Understand requirements and constraints
2. Core Approach - Choose optimal algorithm or solution
3. Implementation Steps - Specific steps to solve

ã€Complexity Analysisã€‘
â€¢ Time Complexity: O(?)
â€¢ Space Complexity: O(?)

ã€Code Implementationã€‘
```python
# Provide complete code solution
def solution():
    pass
```

ã€Key Pointsã€‘
â€¢ Important implementation details
â€¢ Common pitfalls to avoid
â€¢ Optimization suggestions

User Question: {user_text}"""
        else:
            prompt = """Please analyze the content on the screen and provide a structured response:

ã€Analysis & Solutionã€‘
1. Problem Analysis - Understand requirements and constraints
2. Core Approach - Choose optimal algorithm or solution  
3. Implementation Steps - Specific steps to solve

ã€Complexity Analysisã€‘
â€¢ Time Complexity: O(?)
â€¢ Space Complexity: O(?)

ã€Code Implementationã€‘
```python
# Provide complete code solution
def solution():
    pass
```

ã€Key Pointsã€‘
â€¢ Important implementation details
â€¢ Common pitfalls to avoid
â€¢ Optimization suggestions"""
        
        return prompt
    
    async def analyze_screen(self, image: Image.Image, user_text: str = "") -> Optional[str]:
        """åˆ†æå±å¹•å›¾åƒå¹¶è¿”å›AIå“åº”"""
        if not self.client:
            logger.error("OpenAI client not initialized")
            return None
        
        try:
            # è½¬æ¢å›¾åƒä¸ºbase64
            img_base64 = self.image_to_base64(image)
            
            # åˆ›å»ºæç¤ºè¯
            prompt = self.create_analysis_prompt(user_text)
            
            logger.info(f"ğŸ§  Sending analysis request to OpenAI...")
            logger.debug(f"Prompt preview: {prompt[:100]}...")
            
            # å‡†å¤‡æ¶ˆæ¯
            messages = [
                {
                    "role": "system",
                    "content": "You are a helpful programming assistant. Analyze the provided screenshot to understand what the user is working on and provide relevant coding assistance. Focus on technical analysis, code suggestions, and programming guidance. Always respond in English. If you see code, development tools, or programming interfaces, provide detailed technical assistance."
                },
                {
                    "role": "user",
                    "content": [
                        {
                            "type": "text",
                            "text": prompt
                        },
                        {
                            "type": "image_url",
                            "image_url": {
                                "url": f"data:image/png;base64,{img_base64}",
                                "detail": "high"
                            }
                        }
                    ]
                }
            ]
            
            # å‘é€è¯·æ±‚
            response = self.client.chat.completions.create(
                model=self.model,
                messages=messages,
                max_tokens=1000,
                stream=True,
                temperature=0.3  # é™ä½éšæœºæ€§ï¼Œæé«˜å‡†ç¡®æ€§
            )
            
            # æ”¶é›†æµå¼å“åº”
            full_response = ""
            async for chunk in self._process_stream_response(response):
                full_response += chunk
            
            if full_response.strip():
                # å­˜å‚¨åˆ°å¯¹è¯å†å²
                self.conversation_history.append((user_text or "[Screen Analysis]", full_response))
                logger.info(f"âœ… Received response from OpenAI ({len(full_response)} chars)")
                return full_response
            else:
                logger.warning("Empty response from OpenAI")
                return None
                
        except Exception as e:
            logger.error(f"Error in screen analysis: {e}")
            return f"åˆ†æå‡ºé”™: {str(e)}"
    
    async def analyze_multiple_screens(self, images: List[Image.Image], user_text: str = "") -> Optional[str]:
        """åˆ†æå¤šå¼ å±å¹•å›¾åƒå¹¶è¿”å›AIå“åº”"""
        if not self.client:
            logger.error("OpenAI client not initialized")
            return None
        
        if not images:
            logger.warning("No images provided for analysis")
            return None
        
        try:
            logger.info(f"ğŸ§  Sending multi-screen analysis request to OpenAI ({len(images)} images)...")
            
            # ä¸ºå¤šå¼ å›¾ç‰‡åˆ›å»ºç‰¹æ®Šçš„æç¤ºè¯
            if user_text.strip():
                prompt = f"""Please analyze all the screenshots provided and provide a comprehensive response:

ã€Multi-Screen Analysisã€‘
I have provided {len(images)} screenshots for analysis. Please:
1. Analyze each screenshot individually
2. Identify relationships and context between the screens
3. Provide integrated insights and solutions

ã€Analysis & Solutionã€‘
1. Problem Analysis - Understand requirements and constraints across all screens
2. Core Approach - Choose optimal solution considering all contexts
3. Implementation Steps - Specific steps to solve based on complete picture

ã€Code Implementationã€‘
```python
# Provide complete code solution based on all screens
def solution():
    pass
```

ã€Key Insightsã€‘
â€¢ Cross-screen relationships and dependencies
â€¢ Important implementation details from all contexts
â€¢ Optimization suggestions based on complete analysis

User Question: {user_text}"""
            else:
                prompt = f"""Please analyze all {len(images)} screenshots provided and provide a comprehensive response:

ã€Multi-Screen Analysisã€‘
I have provided {len(images)} screenshots for analysis. Please:
1. Analyze each screenshot individually  
2. Identify relationships and context between the screens
3. Provide integrated insights and solutions

ã€Analysis & Solutionã€‘
1. Problem Analysis - Understand requirements across all screens
2. Core Approach - Choose optimal solution considering all contexts
3. Implementation Steps - Specific steps based on complete picture

ã€Code Implementationã€‘
```python
# Provide complete code solution based on all screens
def solution():
    pass
```

ã€Key Insightsã€‘
â€¢ Cross-screen relationships and dependencies
â€¢ Important implementation details from all contexts
â€¢ Common patterns and optimization opportunities"""
            
            # å‡†å¤‡ç”¨æˆ·å†…å®¹ï¼ŒåŒ…å«æ–‡æœ¬å’Œæ‰€æœ‰å›¾ç‰‡
            user_content = [
                {
                    "type": "text",
                    "text": prompt
                }
            ]
            
            # ä¸ºæ¯å¼ å›¾ç‰‡æ·»åŠ åˆ°å†…å®¹ä¸­
            for i, image in enumerate(images):
                img_base64 = self.image_to_base64(image)
                user_content.append({
                    "type": "image_url",
                    "image_url": {
                        "url": f"data:image/png;base64,{img_base64}",
                        "detail": "high"
                    }
                })
                logger.debug(f"Added image {i+1}/{len(images)} to analysis request")
            
            # å‡†å¤‡æ¶ˆæ¯
            messages = [
                {
                    "role": "system",
                    "content": "You are a helpful programming assistant. Analyze all the provided screenshots to understand the complete context of what the user is working on. Look for relationships between the screens and provide comprehensive coding assistance. Focus on technical analysis, integrated solutions, and programming guidance that considers the full picture. Always respond in English."
                },
                {
                    "role": "user",
                    "content": user_content
                }
            ]
            
            # å‘é€è¯·æ±‚ï¼ˆå¤šå›¾ç‰‡å¯èƒ½éœ€è¦æ›´å¤štokenï¼‰
            response = self.client.chat.completions.create(
                model=self.model,
                messages=messages,
                max_tokens=1500,  # å¢åŠ tokenæ•°é‡ä»¥å¤„ç†å¤šå›¾ç‰‡åˆ†æ
                stream=True,
                temperature=0.3
            )
            
            # æ”¶é›†æµå¼å“åº”
            full_response = ""
            async for chunk in self._process_stream_response(response):
                full_response += chunk
            
            if full_response.strip():
                # å­˜å‚¨åˆ°å¯¹è¯å†å²
                image_context = f"[Multi-Screen Analysis: {len(images)} images]"
                self.conversation_history.append((user_text or image_context, full_response))
                logger.info(f"âœ… Received multi-screen response from OpenAI ({len(full_response)} chars)")
                return full_response
            else:
                logger.warning("Empty response from OpenAI")
                return None
                
        except Exception as e:
            logger.error(f"Error in multi-screen analysis: {e}")
            return f"å¤šå±å¹•åˆ†æå‡ºé”™: {str(e)}"
    
    async def _process_stream_response(self, response) -> AsyncGenerator[str, None]:
        """å¤„ç†æµå¼å“åº”"""
        try:
            for chunk in response:
                if chunk.choices[0].delta.content:
                    content = chunk.choices[0].delta.content
                    yield content
        except Exception as e:
            logger.error(f"Error processing stream response: {e}")
            yield f"å“åº”å¤„ç†å‡ºé”™: {str(e)}"
    
    async def analyze_text_only(self, user_text: str) -> Optional[str]:
        """çº¯æ–‡æœ¬åˆ†æï¼Œä¸æ¶‰åŠå›¾åƒ"""
        if not self.client:
            logger.error("OpenAI client not initialized")
            return None
        
        try:
            logger.info(f"ğŸ§  Sending text-only request to OpenAI...")
            logger.debug(f"User text: {user_text}")
            
            # å‡†å¤‡æ¶ˆæ¯ - çº¯æ–‡æœ¬å¯¹è¯
            messages = [
                {
                    "role": "system", 
                    "content": "You are a helpful assistant. Answer the user's question clearly and helpfully in English. If the question is about programming, provide coding assistance and explanations."
                },
                {
                    "role": "user",
                    "content": user_text
                }
            ]
            
            # å‘é€è¯·æ±‚
            response = self.client.chat.completions.create(
                model=self.model,
                messages=messages,
                max_tokens=1000,
                stream=True,
                temperature=0.7  # å¯¹è¯æ¨¡å¼å¯ä»¥ç¨å¾®æé«˜åˆ›é€ æ€§
            )
            
            # æ”¶é›†æµå¼å“åº”
            full_response = ""
            async for chunk in self._process_stream_response(response):
                full_response += chunk
            
            if full_response.strip():
                # æ·»åŠ åˆ°å¯¹è¯å†å²ï¼ˆéœ€è¦é€‚é…æ–°çš„å†å²æ ¼å¼ï¼‰
                self.conversation_history.append((user_text, full_response.strip()))
                
                logger.info(f"âœ… Received text-only response from OpenAI ({len(full_response)} chars)")
                return full_response.strip()
            else:
                logger.warning("Empty response from OpenAI")
                return None
            
        except Exception as e:
            logger.error(f"OpenAI text-only API error: {e}")
            return None
    
    def get_conversation_history(self) -> str:
        """è·å–æ ¼å¼åŒ–çš„å¯¹è¯å†å²"""
        if not self.conversation_history:
            return "Ready..."
        
        history_text = "\n---\n".join(
            f"Q: {q if q.strip() else '[No question]'}\nA: {a}" 
            for q, a in self.conversation_history
        )
        return history_text
    
    def clear_history(self):
        """æ¸…é™¤å¯¹è¯å†å²"""
        self.conversation_history.clear()
        logger.info("ğŸ§¹ Conversation history cleared")
    
    def get_history_count(self) -> int:
        """è·å–å¯¹è¯å†å²æ•°é‡"""
        return len(self.conversation_history)
    
    def export_history(self, filename: str = None) -> str:
        """å¯¼å‡ºå¯¹è¯å†å²åˆ°æ–‡ä»¶"""
        if not filename:
            from datetime import datetime
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            filename = f"ghostmentor_history_{timestamp}.txt"
        
        try:
            with open(filename, 'w', encoding='utf-8') as f:
                f.write("GhostMentor Conversation History\n")
                f.write("=" * 50 + "\n\n")
                
                for i, (question, answer) in enumerate(self.conversation_history, 1):
                    f.write(f"Session {i}\n")
                    f.write("-" * 20 + "\n")
                    f.write(f"Question: {question}\n\n")
                    f.write(f"Answer:\n{answer}\n\n")
                    f.write("=" * 50 + "\n\n")
            
            logger.info(f"ğŸ“„ History exported to {filename}")
            return filename
        except Exception as e:
            logger.error(f"Failed to export history: {e}")
            return None

# å…¨å±€APIç®¡ç†å™¨å®ä¾‹
api_manager = APIManager()

