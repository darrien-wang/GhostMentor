#!/usr/bin/env python3
"""
GhostMentor API Manager
å¤„ç†OpenAI APIç›¸å…³åŠŸèƒ½
"""

import asyncio
import base64
import io
import numpy as np
import cv2
import openai
from PIL import Image
from typing import Optional, List, Tuple, AsyncGenerator
from config_manager import config
from logger_manager import get_logger

logger = get_logger(__name__)

class APIManager:
    """OpenAI APIç®¡ç†å™¨"""
    
    def __init__(self):
        self.client = None
        self.model = config.get('openai_model', 'gpt-4o')
        self.conversation_history: List[Tuple[str, str]] = []
        self.setup_client()
    
    def setup_client(self):
        """åˆå§‹åŒ–OpenAIå®¢æˆ·ç«¯"""
        try:
            api_key = config.get('openai_api_key')
            if not api_key:
                raise ValueError("OpenAI API key not found")
            
            self.client = openai.OpenAI(api_key=api_key)
            logger.info(f"ğŸ¤– OpenAI client initialized with model: {self.model}")
        except Exception as e:
            logger.error(f"Failed to initialize OpenAI client: {e}")
            raise
    
    def image_to_base64(self, image: Image.Image) -> str:
        """å°†PILå›¾åƒè½¬æ¢ä¸ºbase64ç¼–ç """
        try:
            # è½¬æ¢ä¸ºnumpyæ•°ç»„
            img_array = np.array(image)
            # è½¬æ¢é¢œè‰²ç©ºé—´ï¼ˆPILä½¿ç”¨RGBï¼ŒOpenCVä½¿ç”¨BGRï¼‰
            img_rgb = cv2.cvtColor(img_array, cv2.COLOR_RGB2BGR)
            # ç¼–ç ä¸ºPNG
            _, buffer = cv2.imencode('.png', img_rgb)
            # è½¬æ¢ä¸ºbase64
            img_base64 = base64.b64encode(buffer).decode('utf-8')
            logger.debug(f"Image converted to base64, size: {len(img_base64)} chars")
            return img_base64
        except Exception as e:
            logger.error(f"Error converting image to base64: {e}")
            raise
    
    def create_analysis_prompt(self, user_text: str = "") -> str:
        """åˆ›å»ºåˆ†ææç¤ºè¯"""
        if user_text.strip():
            prompt = f"""è¯·åˆ†æå±å¹•ä¸Šçš„é¢˜ç›®ï¼ŒæŒ‰ä»¥ä¸‹æ ¼å¼è¾“å‡ºï¼š

ã€è§£é¢˜æ€è·¯ã€‘
1. é—®é¢˜åˆ†æ - ç†è§£é¢˜ç›®è¦æ±‚å’Œçº¦æŸæ¡ä»¶
2. æ ¸å¿ƒæ€è·¯ - é€‰æ‹©æœ€ä¼˜ç®—æ³•æˆ–è§£å†³æ–¹æ¡ˆ
3. ç®—æ³•æ­¥éª¤ - å…·ä½“å®ç°æ­¥éª¤

ã€å¤æ‚åº¦åˆ†æã€‘
â€¢ æ—¶é—´å¤æ‚åº¦ï¼šO(?)
â€¢ ç©ºé—´å¤æ‚åº¦ï¼šO(?)

ã€ä»£ç å®ç°ã€‘
```python
# æä¾›å®Œæ•´çš„ä»£ç è§£å†³æ–¹æ¡ˆ
def solution():
    pass
```

ã€å…³é”®ç‚¹æç¤ºã€‘
â€¢ é‡è¦çš„å®ç°ç»†èŠ‚
â€¢ æ˜“é”™ç‚¹æé†’
â€¢ ä¼˜åŒ–å»ºè®®

ç”¨æˆ·é—®é¢˜: {user_text}"""
        else:
            prompt = """è¯·åˆ†æå±å¹•ä¸Šçš„é¢˜ç›®ï¼ŒæŒ‰ä»¥ä¸‹æ ¼å¼è¾“å‡ºï¼š

ã€è§£é¢˜æ€è·¯ã€‘
1. é—®é¢˜åˆ†æ - ç†è§£é¢˜ç›®è¦æ±‚å’Œçº¦æŸæ¡ä»¶
2. æ ¸å¿ƒæ€è·¯ - é€‰æ‹©æœ€ä¼˜ç®—æ³•æˆ–è§£å†³æ–¹æ¡ˆ  
3. ç®—æ³•æ­¥éª¤ - å…·ä½“å®ç°æ­¥éª¤

ã€å¤æ‚åº¦åˆ†æã€‘
â€¢ æ—¶é—´å¤æ‚åº¦ï¼šO(?)
â€¢ ç©ºé—´å¤æ‚åº¦ï¼šO(?)

ã€ä»£ç å®ç°ã€‘
```python
# æä¾›å®Œæ•´çš„ä»£ç è§£å†³æ–¹æ¡ˆ
def solution():
    pass
```

ã€å…³é”®ç‚¹æç¤ºã€‘
â€¢ é‡è¦çš„å®ç°ç»†èŠ‚
â€¢ æ˜“é”™ç‚¹æé†’
â€¢ ä¼˜åŒ–å»ºè®®"""
        
        return prompt
    
    async def analyze_screen(self, image: Image.Image, user_text: str = "") -> Optional[str]:
        """åˆ†æå±å¹•å›¾åƒå¹¶è¿”å›AIå“åº”"""
        if not self.client:
            logger.error("OpenAI client not initialized")
            return None
        
        try:
            # è½¬æ¢å›¾åƒä¸ºbase64
            img_base64 = self.image_to_base64(image)
            
            # åˆ›å»ºæç¤ºè¯
            prompt = self.create_analysis_prompt(user_text)
            
            logger.info(f"ğŸ§  Sending analysis request to OpenAI...")
            logger.debug(f"Prompt preview: {prompt[:100]}...")
            
            # å‡†å¤‡æ¶ˆæ¯
            messages = [
                {
                    "role": "system",
                    "content": "You are an expert coding assistant specialized in problem analysis and solution guidance. Provide clear, structured responses in Chinese."
                },
                {
                    "role": "user",
                    "content": [
                        {
                            "type": "text",
                            "text": prompt
                        },
                        {
                            "type": "image_url",
                            "image_url": {
                                "url": f"data:image/png;base64,{img_base64}",
                                "detail": "high"
                            }
                        }
                    ]
                }
            ]
            
            # å‘é€è¯·æ±‚
            response = self.client.chat.completions.create(
                model=self.model,
                messages=messages,
                max_tokens=1000,
                stream=True,
                temperature=0.3  # é™ä½éšæœºæ€§ï¼Œæé«˜å‡†ç¡®æ€§
            )
            
            # æ”¶é›†æµå¼å“åº”
            full_response = ""
            async for chunk in self._process_stream_response(response):
                full_response += chunk
            
            if full_response.strip():
                # å­˜å‚¨åˆ°å¯¹è¯å†å²
                self.conversation_history.append((user_text or "[Screen Analysis]", full_response))
                logger.info(f"âœ… Received response from OpenAI ({len(full_response)} chars)")
                return full_response
            else:
                logger.warning("Empty response from OpenAI")
                return None
                
        except Exception as e:
            logger.error(f"Error in screen analysis: {e}")
            return f"åˆ†æå‡ºé”™: {str(e)}"
    
    async def _process_stream_response(self, response) -> AsyncGenerator[str, None]:
        """å¤„ç†æµå¼å“åº”"""
        try:
            for chunk in response:
                if chunk.choices[0].delta.content:
                    content = chunk.choices[0].delta.content
                    yield content
        except Exception as e:
            logger.error(f"Error processing stream response: {e}")
            yield f"å“åº”å¤„ç†å‡ºé”™: {str(e)}"
    
    def get_conversation_history(self) -> str:
        """è·å–æ ¼å¼åŒ–çš„å¯¹è¯å†å²"""
        if not self.conversation_history:
            return "Ready..."
        
        history_text = "\n---\n".join(
            f"Q: {q if q.strip() else '[No question]'}\nA: {a}" 
            for q, a in self.conversation_history
        )
        return history_text
    
    def clear_history(self):
        """æ¸…é™¤å¯¹è¯å†å²"""
        self.conversation_history.clear()
        logger.info("ğŸ§¹ Conversation history cleared")
    
    def get_history_count(self) -> int:
        """è·å–å¯¹è¯å†å²æ•°é‡"""
        return len(self.conversation_history)
    
    def export_history(self, filename: str = None) -> str:
        """å¯¼å‡ºå¯¹è¯å†å²åˆ°æ–‡ä»¶"""
        if not filename:
            from datetime import datetime
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            filename = f"ghostmentor_history_{timestamp}.txt"
        
        try:
            with open(filename, 'w', encoding='utf-8') as f:
                f.write("GhostMentor Conversation History\n")
                f.write("=" * 50 + "\n\n")
                
                for i, (question, answer) in enumerate(self.conversation_history, 1):
                    f.write(f"Session {i}\n")
                    f.write("-" * 20 + "\n")
                    f.write(f"Question: {question}\n\n")
                    f.write(f"Answer:\n{answer}\n\n")
                    f.write("=" * 50 + "\n\n")
            
            logger.info(f"ğŸ“„ History exported to {filename}")
            return filename
        except Exception as e:
            logger.error(f"Failed to export history: {e}")
            return None

# å…¨å±€APIç®¡ç†å™¨å®ä¾‹
api_manager = APIManager()

