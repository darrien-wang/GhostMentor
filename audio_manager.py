#!/usr/bin/env python3
"""
GhostMentor Audio Manager
å¤„ç†éŸ³é¢‘å½•åˆ¶å’Œè¯­éŸ³è¯†åˆ«åŠŸèƒ½
"""

import numpy as np
import threading
import time
from typing import Optional, Callable
from queue import Queue
from config_manager import config
from logger_manager import get_logger

logger = get_logger(__name__)

class AudioManager:
    """éŸ³é¢‘ç®¡ç†å™¨"""
    
    def __init__(self, use_speech: bool = True):
        self.use_speech = use_speech
        self.audio = None
        self.stream = None
        self.whisper_model = None
        self.audio_buffer = []
        self.current_transcript = ""
        self.is_recording = False
        self.transcription_thread = None
        self.transcript_callback: Optional[Callable[[str], None]] = None
        
        if self.use_speech:
            self.setup_audio()
    
    def setup_audio(self):
        """åˆå§‹åŒ–éŸ³é¢‘ç³»ç»Ÿ"""
        if not self.use_speech:
            logger.info("ğŸ”‡ Audio disabled - running in silent mode")
            return
        
        try:
            # åŠ¨æ€å¯¼å…¥éŸ³é¢‘ç›¸å…³åº“
            import pyaudio
            from faster_whisper import WhisperModel
            
            # è·å–éŸ³é¢‘é…ç½®
            audio_settings = config.get_audio_settings()
            
            # åˆå§‹åŒ–Whisperæ¨¡å‹
            model_size = audio_settings['whisper_model']
            logger.info(f"ğŸ§  Loading Whisper model: {model_size}")
            self.whisper_model = WhisperModel(
                model_size, 
                device="cpu", 
                compute_type="int8"
            )
            logger.info(f"âœ… Whisper model '{model_size}' loaded successfully")
            
            # åˆå§‹åŒ–PyAudio
            self.audio = pyaudio.PyAudio()
            self.stream = self.audio.open(
                format=pyaudio.paInt16,
                channels=1,
                rate=audio_settings['sampling_rate'],
                input=True,
                frames_per_buffer=audio_settings['chunk_size']
            )
            
            logger.info(f"ğŸ¤ Audio stream initialized:")
            logger.info(f"   Sample rate: {audio_settings['sampling_rate']} Hz")
            logger.info(f"   Chunk size: {audio_settings['chunk_size']}")
            logger.info(f"   Buffer duration: {audio_settings['buffer_duration']}s")
            
        except ImportError as e:
            logger.error(f"Audio libraries not available: {e}")
            self.use_speech = False
        except Exception as e:
            logger.error(f"Audio setup error: {e}")
            self.use_speech = False
            raise
    
    def set_transcript_callback(self, callback: Callable[[str], None]):
        """è®¾ç½®è½¬å½•ç»“æœå›è°ƒå‡½æ•°"""
        self.transcript_callback = callback
    
    def start_recording(self):
        """å¼€å§‹å½•éŸ³å’Œè½¬å½•"""
        if not self.use_speech or self.is_recording:
            return
        
        try:
            self.is_recording = True
            self.stream.start_stream()
            
            # å¯åŠ¨è½¬å½•çº¿ç¨‹
            self.transcription_thread = threading.Thread(
                target=self._transcription_worker,
                daemon=True
            )
            self.transcription_thread.start()
            
            logger.info("ğŸ¤ Audio recording started")
            
        except Exception as e:
            logger.error(f"Failed to start recording: {e}")
            self.is_recording = False
    
    def stop_recording(self):
        """åœæ­¢å½•éŸ³"""
        if not self.use_speech or not self.is_recording:
            return
        
        try:
            self.is_recording = False
            
            if self.stream and self.stream.is_active():
                self.stream.stop_stream()
            
            logger.info("ğŸ”‡ Audio recording stopped")
            
        except Exception as e:
            logger.error(f"Error stopping recording: {e}")
    
    def _transcription_worker(self):
        """è½¬å½•å·¥ä½œçº¿ç¨‹"""
        if not self.use_speech or not self.whisper_model:
            return
        
        audio_settings = config.get_audio_settings()
        sampling_rate = audio_settings['sampling_rate']
        chunk_size = audio_settings['chunk_size']
        buffer_duration = audio_settings['buffer_duration']
        buffer_frames = sampling_rate * buffer_duration
        
        logger.info("ğŸ¯ Transcription worker started")
        
        try:
            while self.is_recording:
                try:
                    # è¯»å–éŸ³é¢‘æ•°æ®
                    data = self.stream.read(chunk_size, exception_on_overflow=False)
                    audio_np = np.frombuffer(data, dtype=np.int16).astype(np.float32) / 32768.0
                    self.audio_buffer.append(audio_np)
                    
                    # å½“ç¼“å†²åŒºè¾¾åˆ°æŒ‡å®šæ—¶é•¿æ—¶è¿›è¡Œè½¬å½•
                    total_frames = len(self.audio_buffer) * chunk_size
                    if total_frames >= buffer_frames:
                        self._process_audio_buffer(sampling_rate)
                        
                except Exception as e:
                    logger.error(f"Transcription error: {e}")
                    time.sleep(0.1)  # çŸ­æš‚ä¼‘æ¯åç»§ç»­
                    
        except Exception as e:
            logger.error(f"Transcription worker error: {e}")
        finally:
            logger.info("ğŸ Transcription worker stopped")
    
    def _process_audio_buffer(self, sampling_rate: int):
        """å¤„ç†éŸ³é¢‘ç¼“å†²åŒº"""
        if not self.audio_buffer:
            return
        
        try:
            # åˆå¹¶éŸ³é¢‘æ•°æ®
            full_audio = np.concatenate(self.audio_buffer)
            self.audio_buffer = []  # æ¸…ç©ºç¼“å†²åŒº
            
            duration = len(full_audio) / sampling_rate
            logger.debug(f"ğŸµ Processing audio buffer: {duration:.2f}s")
            
            # ä½¿ç”¨Whisperè¿›è¡Œè½¬å½•
            segments, info = self.whisper_model.transcribe(
                full_audio, 
                beam_size=5,
                language='en',  # å¯ä»¥è®¾ä¸ºNoneè®©æ¨¡å‹è‡ªåŠ¨æ£€æµ‹
                condition_on_previous_text=False  # é¿å…é‡å¤
            )
            
            # åˆå¹¶è½¬å½•ç»“æœ
            text = " ".join(segment.text for segment in segments).strip()
            
            if text and len(text) > 2:  # è¿‡æ»¤å¤ªçŸ­çš„è½¬å½•ç»“æœ
                confidence = info.language_probability
                logger.info(f"ğŸ¯ Transcribed: '{text}' (confidence: {confidence:.2f})")
                
                self.current_transcript = text
                
                # è°ƒç”¨å›è°ƒå‡½æ•°
                if self.transcript_callback:
                    self.transcript_callback(text)
            else:
                logger.debug("ğŸ”‡ No meaningful transcription")
                
        except Exception as e:
            logger.error(f"Audio buffer processing error: {e}")
    
    def get_current_transcript(self) -> str:
        """è·å–å½“å‰è½¬å½•æ–‡æœ¬"""
        return self.current_transcript
    
    def clear_transcript(self):
        """æ¸…é™¤å½“å‰è½¬å½•æ–‡æœ¬"""
        self.current_transcript = ""
        logger.debug("ğŸ§¹ Transcript cleared")
    
    def cleanup(self):
        """æ¸…ç†éŸ³é¢‘èµ„æº"""
        try:
            self.stop_recording()
            
            if self.stream:
                self.stream.close()
                self.stream = None
            
            if self.audio:
                self.audio.terminate()
                self.audio = None
            
            logger.info("ğŸ§¹ Audio resources cleaned up")
            
        except Exception as e:
            logger.error(f"Error cleaning up audio resources: {e}")
    
    def is_available(self) -> bool:
        """æ£€æŸ¥éŸ³é¢‘åŠŸèƒ½æ˜¯å¦å¯ç”¨"""
        return self.use_speech and self.whisper_model is not None
    
    def get_status(self) -> dict:
        """è·å–éŸ³é¢‘çŠ¶æ€ä¿¡æ¯"""
        return {
            "enabled": self.use_speech,
            "available": self.is_available(),
            "recording": self.is_recording,
            "transcript": self.current_transcript,
            "buffer_size": len(self.audio_buffer)
        }

# å…¨å±€éŸ³é¢‘ç®¡ç†å™¨å®ä¾‹ï¼ˆåœ¨mainä¸­åˆå§‹åŒ–ï¼‰
audio_manager: Optional[AudioManager] = None

def initialize_audio_manager(use_speech: bool = True) -> AudioManager:
    """åˆå§‹åŒ–å…¨å±€éŸ³é¢‘ç®¡ç†å™¨"""
    global audio_manager
    audio_manager = AudioManager(use_speech)
    return audio_manager

def get_audio_manager() -> Optional[AudioManager]:
    """è·å–éŸ³é¢‘ç®¡ç†å™¨å®ä¾‹"""
    return audio_manager

